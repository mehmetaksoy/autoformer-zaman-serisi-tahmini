{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Hücre 1 (Başarılı Versiyonları Zorlayarak Kurulum)\n",
        "\n",
        "# Lütfen bu hücreyi çalıştırmadan önce \"Disconnect and delete runtime\" ile\n",
        "# Colab çalışma zamanını tamamen sıfırladığınızdan emin olun!\n",
        "\n",
        "print(\"Başarılı olduğu bilinen kütüphane versiyonları kuruluyor...\")\n",
        "\n",
        "# 1. NumPy'yi 1.26.4'e sabitleyelim.\n",
        "!pip install numpy==1.26.4 -q\n",
        "print(\"NumPy 1.26.4 kuruldu.\")\n",
        "\n",
        "# 2. Datasets'i 3.6.0'a sabitleyelim.\n",
        "!pip install datasets==3.6.0 -q\n",
        "print(\"Datasets 3.6.0 kuruldu.\")\n",
        "\n",
        "# 3. Transformers'ı 4.48.3'e sabitleyelim.\n",
        "!pip install transformers==4.48.3 -q\n",
        "print(\"Transformers 4.48.3 kuruldu.\")\n",
        "\n",
        "# 4. Diğer yardımcı kütüphaneler\n",
        "!pip install scikit-learn matplotlib seaborn -q\n",
        "print(\"Scikit-learn, Matplotlib, Seaborn kuruldu/güncellendi.\")\n",
        "\n",
        "print(\"\\nKütüphane kurulumları (Hücre 1) tamamlandı.\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")\n",
        "print(\"!!! LÜTFEN ŞİMDİ Colab Çalışma Zamanını (Runtime -> Restart runtime)      !!!\")\n",
        "print(\"!!! KESİNLİKLE YENİDEN BAŞLATIN.                                         !!!\")\n",
        "print(\"!!! Yeniden başlattıktan sonra Hücre 1'i TEKRAR ÇALIŞTIRMAYIN,           !!!\")\n",
        "print(\"!!! doğrudan Hücre 2'ye (Kütüphane Importları) geçin.                   !!!\")\n",
        "print(\"!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\")"
      ],
      "metadata": {
        "id": "KDzLMaKLSms2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 2 (Düzeltilmiş): Kütüphanelerin Import Edilmesi, Versiyon Kontrolü ve Cihaz Belirleme\n",
        "\n",
        "# Temel ve Hugging Face kütüphanelerinin import edilmesi\n",
        "import transformers\n",
        "import datasets\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn # scikit-learn'ün ana modülü\n",
        "import matplotlib\n",
        "import seaborn as sns\n",
        "import fsspec # fsspec versiyonunu da kontrol edelim\n",
        "import time   # Eğitim/çıkarım sürelerini ölçmek için\n",
        "import sys    # Python versiyonunu almak için eklendi\n",
        "\n",
        "# Hugging Face kütüphanelerinden sık kullanılacak modüller\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "\n",
        "# Cihazı belirleme: GPU varsa GPU, yoksa CPU kullanılacak.\n",
        "# Colab'da GPU kullanmak için: Runtime -> Change runtime type -> Hardware accelerator -> GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# İsteğe bağlı: Daha temiz bir çıktı için uyarıları bastırma\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "\n",
        "print(\"Kütüphaneler başarıyla import edildi.\")\n",
        "print(\"-\" * 50)\n",
        "print(\"KULLANILAN KÜTÜPHANE VERSİYONLARI:\")\n",
        "# Python versiyonu sys modülü kullanılarak düzeltildi:\n",
        "print(f\"  Python Versiyonu (sys.version): {sys.version.split()[0]}\")\n",
        "print(f\"  PyTorch: {torch.__version__}\")\n",
        "print(f\"  Transformers: {transformers.__version__}\")\n",
        "print(f\"  Datasets: {datasets.__version__}\")\n",
        "print(f\"  Numpy: {np.__version__}\")\n",
        "print(f\"  Pandas: {pd.__version__}\")\n",
        "print(f\"  Scikit-learn: {sklearn.__version__}\")\n",
        "print(f\"  Matplotlib: {matplotlib.__version__}\")\n",
        "print(f\"  Seaborn: {sns.__version__}\")\n",
        "print(f\"  fsspec: {fsspec.__version__}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"KULLANILACAK CİHAZ: {device}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# GPU varsa, CUDA ve cuDNN versiyonlarını da yazdıralım (bilgi amaçlı)\n",
        "if device.type == 'cuda':\n",
        "    print(f\"  CUDA Versiyonu (torch.version.cuda): {torch.version.cuda}\")\n",
        "    print(f\"  cuDNN Versiyonu (torch.backends.cudnn.version()): {torch.backends.cudnn.version()}\")\n",
        "    print(f\"  Kullanılabilir GPU Sayısı: {torch.cuda.device_count()}\")\n",
        "    print(f\"  Aktif GPU Adı: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\"-\" * 50)\n",
        "else:\n",
        "    print(\"Uyarı: GPU bulunamadı veya aktif değil. Model eğitimi CPU üzerinde daha yavaş olacaktır.\")\n",
        "    print(\"Colab'da GPU'yu aktifleştirmek için 'Runtime' -> 'Change runtime type' menüsünü kullanabilirsiniz.\")\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "id": "goNWz2PrM44w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 3: IMDB Veri Setinin Yüklenmesi ve Temel İnceleme\n",
        "\n",
        "print(\"IMDB veri seti yükleniyor...\")\n",
        "try:\n",
        "    imdb_dataset_raw = load_dataset(\"imdb\")\n",
        "    print(\"IMDB veri seti başarıyla yüklendi.\")\n",
        "    print(\"\\nYüklenen Ham Veri Seti Yapısı:\")\n",
        "    print(imdb_dataset_raw)\n",
        "\n",
        "    # label_feature'ı global yaparak diğer hücrelerden erişilebilir kılalım.\n",
        "    # Bu, Hücre 2'de import edilen datasets kütüphanesini kullanır.\n",
        "    global label_feature\n",
        "    label_feature = imdb_dataset_raw['train'].features['label']\n",
        "\n",
        "    print(\"\\nEtiket Bilgisi (ClassLabel):\")\n",
        "    print(label_feature)\n",
        "    print(f\"Etiket 0: {label_feature.int2str(0)}\") # neg\n",
        "    print(f\"Etiket 1: {label_feature.int2str(1)}\") # pos\n",
        "\n",
        "    # 'unsupervised' alt kümesini çıkararak yeni bir DatasetDict oluşturalım\n",
        "    keys_to_keep = ['train', 'test']\n",
        "    imdb_dataset_processed = datasets.DatasetDict(\n",
        "        {k: imdb_dataset_raw[k] for k in keys_to_keep if k in imdb_dataset_raw}\n",
        "    )\n",
        "\n",
        "    if 'unsupervised' not in imdb_dataset_processed and 'unsupervised' in imdb_dataset_raw:\n",
        "        print(\"\\n'unsupervised' alt kümesi başarıyla işlenmiş veri setinden çıkarıldı.\")\n",
        "    elif 'unsupervised' not in imdb_dataset_raw:\n",
        "        print(\"\\n'unsupervised' alt kümesi zaten ham veri setinde bulunmuyordu.\")\n",
        "    else: # Bu durumun oluşmaması gerekir eğer pop veya yeniden oluşturma doğruysa\n",
        "        print(\"\\n'unsupervised' alt kümesi işlenmiş veri setinde hala mevcut veya bir sorun oluştu.\")\n",
        "\n",
        "    print(\"\\nİşlenmiş (Relevant) Veri Seti Yapısı:\")\n",
        "    print(imdb_dataset_processed)\n",
        "\n",
        "    if 'train' in imdb_dataset_processed and len(imdb_dataset_processed['train']) > 0:\n",
        "        print(\"\\nEğitim setinden ilk örnek:\")\n",
        "        example = imdb_dataset_processed['train'][0]\n",
        "        print(f\"  Metin: {example['text'][:200]}...\") # İlk 200 karakter\n",
        "        print(f\"  Etiket: {example['label']} ({label_feature.int2str(example['label'])})\")\n",
        "    else:\n",
        "        print(\"\\nEğitim seti bulunamadı veya boş.\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nVeri seti yüklenirken veya işlenirken bir hata oluştu: {e}\")\n",
        "    # Hata durumunda değişkenlerin None olarak ayarlanması, sonraki hücrelerde kontrolü kolaylaştırır.\n",
        "    imdb_dataset_processed = None\n",
        "    if 'label_feature' in globals(): del label_feature # Eğer tanımlandıysa silelim"
      ],
      "metadata": {
        "id": "2DLA3KmwM7Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 4 (Düzeltilmiş - scikit-learn ile Bölme): Veri Setini Eğitim, Doğrulama ve Test Alt Kümelerine Ayırma\n",
        "\n",
        "from sklearn.model_selection import train_test_split as sk_train_test_split\n",
        "\n",
        "# Gerekli değişkenlerin bir önceki hücreden geldiğini varsayıyoruz\n",
        "if 'imdb_dataset_processed' in globals() and imdb_dataset_processed is not None and 'train' in imdb_dataset_processed and \\\n",
        "   'label_feature' in globals() and label_feature is not None:\n",
        "    print(\"Mevcut 'train' seti, scikit-learn kullanılarak 'validation' seti oluşturmak üzere bölünüyor...\")\n",
        "\n",
        "    train_texts_list = imdb_dataset_processed['train']['text']\n",
        "    train_labels_list = imdb_dataset_processed['train']['label']\n",
        "\n",
        "    new_train_texts, validation_texts, new_train_labels, validation_labels = sk_train_test_split(\n",
        "        train_texts_list,\n",
        "        train_labels_list,\n",
        "        test_size=0.2,\n",
        "        random_state=42,\n",
        "        stratify=train_labels_list\n",
        "    )\n",
        "\n",
        "    original_features = imdb_dataset_processed['train'].features\n",
        "\n",
        "    train_dataset_new = datasets.Dataset.from_dict(\n",
        "        {'text': new_train_texts, 'label': new_train_labels},\n",
        "        features=original_features\n",
        "    )\n",
        "    validation_dataset_new = datasets.Dataset.from_dict(\n",
        "        {'text': validation_texts, 'label': validation_labels},\n",
        "        features=original_features\n",
        "    )\n",
        "\n",
        "    # final_imdb_dataset'i global yapalım ki diğer hücrelerden erişilebilsin\n",
        "    global final_imdb_dataset\n",
        "    final_imdb_dataset = datasets.DatasetDict({\n",
        "        'train': train_dataset_new,\n",
        "        'validation': validation_dataset_new,\n",
        "        'test': imdb_dataset_processed['test']\n",
        "    })\n",
        "\n",
        "    print(\"\\nNihai Veri Seti Yapısı (Eğitim, Doğrulama, Test):\")\n",
        "    print(final_imdb_dataset)\n",
        "\n",
        "    print(f\"\\nEğitim seti örnek sayısı: {len(final_imdb_dataset['train'])}\")\n",
        "    print(f\"Doğrulama seti örnek sayısı: {len(final_imdb_dataset['validation'])}\")\n",
        "    print(f\"Test seti örnek sayısı: {len(final_imdb_dataset['test'])}\")\n",
        "\n",
        "    def get_label_distribution(dataset_split, current_label_feature):\n",
        "        if not dataset_split: return \"Veri seti objesi None.\"\n",
        "        if len(dataset_split) == 0: return \"Veri seti boş.\"\n",
        "        try:\n",
        "            labels = dataset_split['label']\n",
        "            series = pd.Series(labels).value_counts().sort_index()\n",
        "            # current_label_feature'ın None olup olmadığını ve int2str metoduna sahip olup olmadığını kontrol et\n",
        "            if current_label_feature is not None and hasattr(current_label_feature, 'int2str'):\n",
        "                 return series.rename(index=current_label_feature.int2str)\n",
        "            return series\n",
        "        except Exception as e: return f\"Etiket dağılımı hesaplanırken hata: {e}\"\n",
        "\n",
        "    print(\"\\nEğitim Seti Etiket Dağılımı:\")\n",
        "    print(get_label_distribution(final_imdb_dataset['train'], label_feature))\n",
        "\n",
        "    print(\"\\nDoğrulama Seti Etiket Dağılımı:\")\n",
        "    print(get_label_distribution(final_imdb_dataset['validation'], label_feature))\n",
        "\n",
        "    print(\"\\nTest Seti Etiket Dağılımı:\")\n",
        "    print(get_label_distribution(final_imdb_dataset['test'], label_feature))\n",
        "else:\n",
        "    print(\"Hata: 'imdb_dataset_processed' veya 'label_feature' doğru şekilde tanımlanmamış. Bu hücre çalıştırılamadı.\")\n",
        "    if 'final_imdb_dataset' in globals(): del final_imdb_dataset"
      ],
      "metadata": {
        "id": "aAlSKtaQNR1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 5: BERT Tokenizer'ının Yüklenmesi ve Veri Setinin Tokenizasyonu\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"bert-base-uncased\"\n",
        "print(f\"Kullanılacak model checkpoint: {model_checkpoint}\")\n",
        "\n",
        "# final_imdb_dataset'in Hücre 4'te tanımlandığını varsayıyoruz\n",
        "if 'final_imdb_dataset' in globals() and final_imdb_dataset is not None:\n",
        "    try:\n",
        "        # tokenizer'ı global yapalım ki diğer hücrelerden erişilebilsin\n",
        "        global tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "        print(f\"\\n'{model_checkpoint}' için tokenizer başarıyla yüklendi.\")\n",
        "\n",
        "        sample_text = \"Hello, this is a sample sentence for tokenization!\"\n",
        "        encoded_sample = tokenizer(sample_text)\n",
        "        print(f\"\\nÖrnek metin: '{sample_text}'\")\n",
        "        print(f\"Tokenize edilmiş hali (input_ids): {encoded_sample['input_ids']}\")\n",
        "        print(f\"Token ID'lerinin tekrar metne dönüştürülmüş hali: {tokenizer.convert_ids_to_tokens(encoded_sample['input_ids'])}\")\n",
        "\n",
        "        def tokenize_function(examples):\n",
        "            return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
        "\n",
        "        print(f\"\\nVeri seti tokenize ediliyor (max_length=256)... Bu işlem biraz zaman alabilir.\")\n",
        "\n",
        "        # tokenized_datasets'i global yapalım\n",
        "        global tokenized_datasets\n",
        "        tokenized_datasets = final_imdb_dataset.map(\n",
        "            tokenize_function,\n",
        "            batched=True,\n",
        "            remove_columns=[\"text\"]\n",
        "        )\n",
        "\n",
        "        tokenized_datasets.set_format(\"torch\")\n",
        "\n",
        "        print(\"\\nVeri seti başarıyla tokenize edildi ve formatı PyTorch tensörlerine ayarlandı.\")\n",
        "        print(\"Tokenize edilmiş veri seti yapısı:\")\n",
        "        print(tokenized_datasets)\n",
        "\n",
        "        if 'train' in tokenized_datasets and len(tokenized_datasets['train']) > 0:\n",
        "            print(\"\\nTokenize edilmiş eğitim setinden ilk örnek:\")\n",
        "            example_item = tokenized_datasets['train'][0]\n",
        "            print(example_item)\n",
        "            if 'input_ids' in example_item and hasattr(example_item['input_ids'], '__len__'):\n",
        "                 print(f\"Input IDs uzunluğu: {len(example_item['input_ids'])}\")\n",
        "            else:\n",
        "                print(\"Örnekte 'input_ids' bulunamadı veya uzunluğu alınamadı.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTokenizer yüklenirken veya tokenizasyon sırasında bir genel hata oluştu: {e}\")\n",
        "        if 'tokenized_datasets' in globals(): del tokenized_datasets\n",
        "        if 'tokenizer' in globals(): del tokenizer\n",
        "else:\n",
        "    print(\"Hata: 'final_imdb_dataset' bulunamadığı için tokenizasyon işlemi başlatılamadı.\")\n",
        "    if 'tokenized_datasets' in globals(): del tokenized_datasets\n",
        "    if 'tokenizer' in globals(): del tokenizer"
      ],
      "metadata": {
        "id": "c6sIO_Y0NXS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 6: Önceden Eğitilmiş BERT Modelinin Yüklenmesi\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "# model_checkpoint, num_labels, device değişkenlerinin önceki hücrelerde tanımlandığını varsayıyoruz\n",
        "# num_labels'ı burada tekrar tanımlayalım veya global olduğundan emin olalım.\n",
        "# Hücre 5'te model_checkpoint, Hücre 2'de device tanımlandı.\n",
        "# num_labels'ı burada tanımlamak daha güvenli olabilir.\n",
        "num_labels = 2\n",
        "\n",
        "if 'model_checkpoint' in globals() and 'num_labels' in globals() and 'device' in globals():\n",
        "    print(f\"'{model_checkpoint}' modeli '{num_labels}' etiket ile sınıflandırma görevi için yükleniyor...\")\n",
        "    try:\n",
        "        # model'i global yapalım\n",
        "        global model\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(\n",
        "            model_checkpoint,\n",
        "            num_labels=num_labels\n",
        "        )\n",
        "\n",
        "        model.to(device)\n",
        "\n",
        "        print(f\"\\nModel başarıyla yüklendi ve '{device}' cihazına taşındı.\")\n",
        "\n",
        "        total_params = sum(p.numel() for p in model.parameters())\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        print(f\"\\nModeldeki toplam parametre sayısı: {total_params:,}\")\n",
        "        print(f\"Modeldeki eğitilebilir parametre sayısı: {trainable_params:,}\")\n",
        "\n",
        "        if hasattr(model.config, 'num_labels'):\n",
        "            print(f\"Modelin yapılandırmasındaki etiket sayısı: {model.config.num_labels}\")\n",
        "        if hasattr(model, 'classifier') and hasattr(model.classifier, 'out_features'):\n",
        "             print(f\"Sınıflandırıcı katmanının çıktı boyutu: {model.classifier.out_features}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nModel yüklenirken bir hata oluştu: {e}\")\n",
        "        if 'model' in globals(): del model\n",
        "else:\n",
        "    print(\"Hata: Gerekli değişkenler ('model_checkpoint', 'num_labels', 'device') bulunamadı.\")\n",
        "    if 'model' in globals(): del model"
      ],
      "metadata": {
        "id": "-i5CDlnNNjGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 7 (Epoch Bazında Değerlendirme ile Güncellenmiş TrainingArguments - Düzeltilmiş `if` koşulu ile):\n",
        "# Eğitim Argümanlarının Tanımlanması, Metrik Hesaplama Fonksiyonu ve Modelin Eğitilmesi\n",
        "\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, confusion_matrix\n",
        "# numpy, torch, time zaten Hücre 2'de import edilmişti.\n",
        "# num_labels, model, tokenized_datasets, tokenizer, device değişkenlerinin\n",
        "# önceki hücrelerde doğru şekilde tanımlandığını ve erişilebilir olduğunu varsayıyoruz.\n",
        "\n",
        "# 1. Performans Metriklerini Hesaplama Fonksiyonu\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "\n",
        "    # num_labels'ın (Hücre 6'da tanımlanmıştı) bu scope'ta erişilebilir olması gerekir.\n",
        "    # Ya global yapın ya da model.config.num_labels kullanın.\n",
        "    # Şimdilik modelin config'inden alalım, daha güvenli.\n",
        "    current_num_labels = model.config.num_labels if 'model' in globals() and model else 2 # Fallback\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    try:\n",
        "        cm = confusion_matrix(labels, preds, labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "    except ValueError:\n",
        "        tn, fp, fn, tp = 0,0,0,0\n",
        "        if len(np.unique(labels)) == 1:\n",
        "            if np.unique(labels)[0] == 0 and (len(np.unique(preds))==0 or (len(np.unique(preds))==1 and np.unique(preds)[0] == 0)): tn = len(labels)\n",
        "            if np.unique(labels)[0] == 1 and (len(np.unique(preds))==0 or (len(np.unique(preds))==1 and np.unique(preds)[0] == 1)): tp = len(labels)\n",
        "\n",
        "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n",
        "\n",
        "    auc_value = 0.0\n",
        "    if pred.predictions.ndim == 2 and pred.predictions.shape[1] == current_num_labels:\n",
        "        try:\n",
        "            logits_tensor = torch.tensor(pred.predictions)\n",
        "            probs = torch.softmax(logits_tensor, dim=-1).cpu().numpy()\n",
        "            positive_class_probs = probs[:, 1]\n",
        "            auc_value = roc_auc_score(labels, positive_class_probs)\n",
        "        except ValueError:\n",
        "            auc_value = 0.0\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1,\n",
        "        'specificity': specificity, 'auc': auc_value\n",
        "    }\n",
        "\n",
        "# 2. Eğitim Argümanları (TrainingArguments) - Epoch bazında değerlendirme ile\n",
        "# Önceki çalışmanızdaki output_dir'den farklı bir isim kullanalım ki sonuçlar karışmasın.\n",
        "training_args_epoch_eval = TrainingArguments(\n",
        "    output_dir=\"./results_epoch_evaluation\", # Yeni çıktı dizini\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",             # <<-- HER EPOCH SONUNDA DEĞERLENDİRME\n",
        "    save_strategy=\"epoch\",                   # <<-- HER EPOCH SONUNDA CHECKPOINT KAYDETME\n",
        "    load_best_model_at_end=True,             # <<-- Eğitim sonunda en iyi modeli yükle\n",
        "    metric_for_best_model=\"accuracy\",        # En iyi modeli 'accuracy' metriğine göre belirle\n",
        "    save_total_limit=2, # En iyi ve son checkpoint'i tutabilir\n",
        "    report_to=\"tensorboard\",\n",
        ")\n",
        "\n",
        "print(f\"\\nEğitim argümanları (epoch bazında değerlendirme ile) tanımlandı. Çıktı dizini: {training_args_epoch_eval.output_dir}\")\n",
        "\n",
        "# 3. Trainer Objesinin Oluşturulması - DÜZELTİLMİŞ `if` KOŞULU\n",
        "if 'model' in globals() and model is not None and \\\n",
        "   'tokenized_datasets' in globals() and tokenized_datasets is not None and \\\n",
        "   'tokenizer' in globals() and tokenizer is not None: # 'device' ve 'training_time' kontrolü çıkarıldı\n",
        "\n",
        "    # trainer'ı global yapalım ki sonraki hücrelerde (örn: Hücre 8) kullanılabilsin\n",
        "    global trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args_epoch_eval,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"validation\"],\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    print(\"\\nTrainer objesi başarıyla oluşturuldu.\")\n",
        "\n",
        "    print(\"\\nModel eğitimi (epoch bazında değerlendirme ile) başlatılıyor...\")\n",
        "    # device ve diğer bilgilerin Hücre 2'de zaten yazdırıldığını varsayıyoruz.\n",
        "    print(f\"Epoch sayısı: {training_args_epoch_eval.num_train_epochs}, Train Batch Size: {training_args_epoch_eval.per_device_train_batch_size}\")\n",
        "\n",
        "    # training_time'ı global yapalım\n",
        "    global training_time\n",
        "    start_time_train_epoch_eval = time.time()\n",
        "    try:\n",
        "        train_result = trainer.train()\n",
        "        end_time_train_epoch_eval = time.time()\n",
        "        training_time = end_time_train_epoch_eval - start_time_train_epoch_eval\n",
        "\n",
        "        print(f\"\\nEğitim tamamlandı! Toplam eğitim süresi: {training_time:.2f} saniye ({training_time/60:.2f} dakika).\")\n",
        "\n",
        "        if hasattr(train_result, 'metrics') and train_result.metrics:\n",
        "            print(\"Genel eğitim sonuç metrikleri (trainer.train() dönüşünden):\")\n",
        "            for key, value in train_result.metrics.items():\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        # load_best_model_at_end=True olduğu için, trainer.model artık en iyi modeli içeriyor.\n",
        "        # Bu en iyi modeli kaydedelim.\n",
        "        best_model_path = f\"{training_args_epoch_eval.output_dir}/best_model\"\n",
        "        trainer.save_model(best_model_path)\n",
        "        tokenizer.save_pretrained(best_model_path)\n",
        "        print(f\"Eğitim sonrası (en iyi) model ve tokenizer '{best_model_path}' adresine kaydedildi.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nModel eğitimi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        if 'train_result' not in globals(): train_result = None\n",
        "        training_time = None # Hata durumunda training_time'ı None yapalım\n",
        "else:\n",
        "    print(\"\\nModel, tokenize edilmiş veri seti veya tokenizer bulunamadığı için Trainer oluşturulamadı ve eğitim başlatılamadı.\")\n",
        "    if 'trainer' in globals(): del trainer\n",
        "    if 'train_result' not in globals(): train_result = None\n",
        "    training_time = None"
      ],
      "metadata": {
        "id": "UqeWrb4RNoh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 8: Eğitilmiş Modelin Test Seti Üzerinde Değerlendirilmesi\n",
        "\n",
        "print(\"Eğitilmiş model test seti üzerinde değerlendiriliyor...\")\n",
        "\n",
        "# Gerekli değişkenlerin varlığını kontrol edelim\n",
        "if 'trainer' in globals() and trainer is not None and \\\n",
        "   'tokenized_datasets' in globals() and \"test\" in tokenized_datasets:\n",
        "    try:\n",
        "        # eval_dataset parametresi ile test setini belirtiyoruz\n",
        "        test_metrics_output = trainer.evaluate(eval_dataset=tokenized_datasets[\"test\"])\n",
        "\n",
        "        print(\"\\nTest Seti Performans Metrikleri:\")\n",
        "        # trainer.evaluate() metriklerin başına 'eval_' ekler\n",
        "        print(f\"  Test Kaybı (Loss): {test_metrics_output.get('eval_loss', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Accuracy: {test_metrics_output.get('eval_accuracy', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Precision: {test_metrics_output.get('eval_precision', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Recall: {test_metrics_output.get('eval_recall', 'N/A'):.4f}\")\n",
        "        print(f\"  Test F1-Score: {test_metrics_output.get('eval_f1', 'N/A'):.4f}\")\n",
        "        print(f\"  Test Specificity: {test_metrics_output.get('eval_specificity', 'N/A'):.4f}\")\n",
        "        print(f\"  Test AUC: {test_metrics_output.get('eval_auc', 'N/A'):.4f}\")\n",
        "\n",
        "        # Metrikleri globalde saklayalım ki Hücre 9'da kullanılabilsin\n",
        "        global bert_test_metrics\n",
        "        bert_test_metrics = test_metrics_output\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTest seti değerlendirmesi sırasında bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "        bert_test_metrics = None # Hata durumunda None olarak ayarla\n",
        "else:\n",
        "    print(\"Hata: 'trainer' objesi veya 'tokenized_datasets['test']' bulunamadı.\")\n",
        "    print(\"Lütfen önceki hücrelerin doğru çalıştığından emin olun.\")\n",
        "    bert_test_metrics = None"
      ],
      "metadata": {
        "id": "uihw1deYNy7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 9: Karmaşıklık Matrisi ve ROC Eğrisinin Çizdirilmesi (Test Seti Üzerinden)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, roc_curve\n",
        "from sklearn.metrics import auc as sklearn_auc # sklearn.metrics.auc'yi import ediyoruz\n",
        "# numpy ve torch zaten import edilmişti\n",
        "\n",
        "# Gerekli değişkenlerin varlığını ve doğruluğunu kontrol edelim\n",
        "if 'trainer' in globals() and trainer is not None and \\\n",
        "   'tokenized_datasets' in globals() and \"test\" in tokenized_datasets and \\\n",
        "   'bert_test_metrics' in globals() and bert_test_metrics is not None and \\\n",
        "   'label_feature' in globals() and label_feature is not None and hasattr(label_feature, 'names') and hasattr(label_feature, 'int2str'):\n",
        "\n",
        "    print(\"Test seti üzerinde tahminler alınıyor...\")\n",
        "    try:\n",
        "        test_predictions_output = trainer.predict(tokenized_datasets[\"test\"])\n",
        "\n",
        "        logits = test_predictions_output.predictions\n",
        "        probabilities = torch.softmax(torch.tensor(logits), dim=-1).cpu().numpy()\n",
        "        predicted_labels = np.argmax(logits, axis=1)\n",
        "        true_labels = test_predictions_output.label_ids\n",
        "\n",
        "        # 1. Karmaşıklık Matrisi (Confusion Matrix)\n",
        "        # Etiketlerin [0, 1] olduğunu ve label_feature.names'in ['neg', 'pos'] olduğunu varsayıyoruz\n",
        "        cm_labels_numeric = [0, 1] # Sayısal etiketler\n",
        "        cm_display_labels = label_feature.names # Görüntülenecek etiketler\n",
        "\n",
        "        cm = confusion_matrix(true_labels, predicted_labels, labels=cm_labels_numeric)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                    xticklabels=cm_display_labels,\n",
        "                    yticklabels=cm_display_labels)\n",
        "        plt.title('Karmaşıklık Matrisi (Test Seti)')\n",
        "        plt.xlabel('Tahmin Edilen Etiket')\n",
        "        plt.ylabel('Gerçek Etiket')\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\nKarmaşıklık Matrisi Değerleri:\")\n",
        "        # cm[0,0]=TN (neg-neg), cm[0,1]=FP (neg-pos), cm[1,0]=FN (pos-neg), cm[1,1]=TP (pos-pos)\n",
        "        print(f\"  Doğru Negatif (TN) [{cm_display_labels[0]}-{cm_display_labels[0]}]: {cm[0,0]}\")\n",
        "        print(f\"  Yanlış Pozitif (FP) [{cm_display_labels[0]}-{cm_display_labels[1]}]: {cm[0,1]}\")\n",
        "        print(f\"  Yanlış Negatif (FN) [{cm_display_labels[1]}-{cm_display_labels[0]}]: {cm[1,0]}\")\n",
        "        print(f\"  Doğru Pozitif (TP) [{cm_display_labels[1]}-{cm_display_labels[1]}]: {cm[1,1]}\")\n",
        "\n",
        "        # 2. ROC Eğrisi\n",
        "        # Pozitif sınıfın ID'sini alalım (genellikle 1)\n",
        "        positive_class_id = label_feature.str2int('pos') if hasattr(label_feature, 'str2int') else 1\n",
        "\n",
        "        # Sadece pozitif sınıfın olasılıklarını alalım\n",
        "        positive_class_probabilities = probabilities[:, positive_class_id]\n",
        "\n",
        "        fpr, tpr, thresholds = roc_curve(true_labels, positive_class_probabilities, pos_label=positive_class_id)\n",
        "        roc_auc_value_sklearn = sklearn_auc(fpr, tpr)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC eğrisi (AUC = {roc_auc_value_sklearn:.4f})')\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--') # Rastgele tahmin çizgisi\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.05])\n",
        "        plt.xlabel('Yanlış Pozitif Oranı (1 - Specificity)')\n",
        "        plt.ylabel('Doğru Pozitif Oranı (Recall/Sensitivity)')\n",
        "        plt.title('Alıcı İşletim Karakteristiği (ROC) Eğrisi')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "        print(f\"\\nHücre 8'de hesaplanan Test AUC (trainer.evaluate): {bert_test_metrics.get('eval_auc', 'N/A'):.4f}\")\n",
        "        print(f\"Bu hücrede ROC eğrisi için hesaplanan AUC (sklearn): {roc_auc_value_sklearn:.4f}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nTahminler alınırken veya görselleştirmeler oluşturulurken bir hata oluştu: {e}\")\n",
        "        import traceback\n",
        "        print(traceback.format_exc())\n",
        "else:\n",
        "    print(\"Hata: Gerekli değişkenler ('trainer', 'tokenized_datasets['test']', 'bert_test_metrics', 'label_feature') bulunamadı veya 'label_feature' doğru yapılandırılmamış.\")\n",
        "    print(\"Lütfen önceki hücrelerin doğru çalıştığından emin olun.\")"
      ],
      "metadata": {
        "id": "HDxNgzzYN2jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 10 (Geliştirilmiş Log İşleme ve Tam Veriyle Grafikler):\n",
        "# Eğitim ve Doğrulama Kayıp/Metrik Grafikleri\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# trainer ve log_history'nin Hücre 7'den geldiğini varsayıyoruz\n",
        "if 'trainer' in globals() and trainer is not None and \\\n",
        "   hasattr(trainer.state, 'log_history') and trainer.state.log_history:\n",
        "\n",
        "    log_history = trainer.state.log_history\n",
        "\n",
        "    print(\"Ham log_history içeriği (ilk 3 ve son 3 kayıt - eğer yeterliyse):\")\n",
        "    # log_history'nin yapısını daha iyi anlamak için birkaç giriş yazdıralım\n",
        "    num_entries_to_show = 3\n",
        "    if len(log_history) > 2 * num_entries_to_show:\n",
        "        for i in range(num_entries_to_show): print(log_history[i])\n",
        "        print(\"...\")\n",
        "        for i in range(len(log_history) - num_entries_to_show, len(log_history)): print(log_history[i])\n",
        "    else:\n",
        "        for entry in log_history: print(entry)\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # log_history'yi bir DataFrame'e dönüştürelim\n",
        "    log_df = pd.DataFrame(log_history)\n",
        "\n",
        "    # Eğitim logları: 'loss' anahtarını içerir ve 'eval_loss' anahtarını içermez\n",
        "    # Ayrıca, 'learning_rate' içerenler genellikle eğitim adımı loglarıdır.\n",
        "    train_logs_df = log_df[log_df['loss'].notna() & log_df['eval_loss'].isna()].copy()\n",
        "\n",
        "    # Değerlendirme logları: 'eval_loss' anahtarını içerir\n",
        "    eval_logs_df = log_df[log_df['eval_loss'].notna()].copy()\n",
        "\n",
        "    # Grafikleri çizdirelim\n",
        "    if not train_logs_df.empty and not eval_logs_df.empty:\n",
        "        plt.figure(figsize=(12, 6))\n",
        "\n",
        "        # Eğitim Kaybı\n",
        "        plt.plot(train_logs_df['epoch'], train_logs_df['loss'], 'b-o', label='Eğitim Kaybı (Training Loss)')\n",
        "\n",
        "        # Doğrulama Kaybı\n",
        "        plt.plot(eval_logs_df['epoch'], eval_logs_df['eval_loss'], 'r-s', label='Doğrulama Kaybı (Validation Loss)')\n",
        "\n",
        "        plt.title('Epoch Bazında Eğitim ve Doğrulama Kaybı')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Kayıp (Loss)')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "        # X ekseni için epoch değerlerini belirle\n",
        "        # Epochlar genellikle tam sayılar (1.0, 2.0, 3.0 ...) veya bunlara çok yakın ondalıklar olur.\n",
        "        # En son log_history'nizde epochlar tam sayıydı.\n",
        "        epochs_present = sorted(list(set(train_logs_df['epoch'].round().tolist() + eval_logs_df['epoch'].round().tolist())))\n",
        "        if epochs_present:\n",
        "            min_e, max_e = min(epochs_present), max(epochs_present)\n",
        "            plt.xticks(np.arange(int(min_e), int(max_e) + 1, 1.0))\n",
        "            plt.xlim(left=int(min_e) - 0.5, right=int(max_e) + 0.5) # Grafiğin kenarlarında biraz boşluk bırak\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "        # Doğrulama doğruluğu grafiği\n",
        "        if 'eval_accuracy' in eval_logs_df.columns and not eval_logs_df['eval_accuracy'].isna().all():\n",
        "            plt.figure(figsize=(12, 6))\n",
        "            plt.plot(eval_logs_df['epoch'], eval_logs_df['eval_accuracy'], 'g-^', label='Doğrulama Doğruluğu (Validation Accuracy)')\n",
        "            plt.title('Epoch Bazında Doğrulama Doğruluğu')\n",
        "            plt.xlabel('Epoch')\n",
        "            plt.ylabel('Doğruluk (Accuracy)')\n",
        "            plt.legend()\n",
        "            plt.grid(True)\n",
        "            if epochs_present: # Aynı x-ekseni ayarını kullanalım\n",
        "                plt.xticks(np.arange(int(min_e), int(max_e) + 1, 1.0))\n",
        "                plt.xlim(left=int(min_e) - 0.5, right=int(max_e) + 0.5)\n",
        "            plt.show()\n",
        "        else:\n",
        "            print(\"\\nDoğrulama doğruluğu ('eval_accuracy') loglarda anlamlı şekilde bulunamadı veya tüm değerler NaN.\")\n",
        "            print(\"Mevcut doğrulama logları (epoch ve eval_accuracy sütunları):\")\n",
        "            if 'epoch' in eval_logs_df and 'eval_accuracy' in eval_logs_df:\n",
        "                print(eval_logs_df[['epoch', 'eval_accuracy']].to_string())\n",
        "            elif 'epoch' in eval_logs_df:\n",
        "                 print(eval_logs_df[['epoch']].to_string())\n",
        "            else:\n",
        "                print(eval_logs_df.to_string())\n",
        "\n",
        "    elif train_logs_df.empty:\n",
        "        print(\"Eğitim logları ('loss' içeren ve 'eval_loss' içermeyen) filtrelenemedi. Ham log_df:\")\n",
        "        print(log_df.to_string())\n",
        "    elif eval_logs_df.empty:\n",
        "        print(\"Doğrulama logları ('eval_loss' içeren) filtrelenemedi. Ham log_df:\")\n",
        "        print(log_df.to_string())\n",
        "    else:\n",
        "        print(\"Grafik çizdirmek için yeterli eğitim veya doğrulama logu bulunamadı.\")\n",
        "\n",
        "else:\n",
        "    print(\"Hata: 'trainer' objesi veya 'log_history' bulunamadı.\")\n",
        "    print(\"Lütfen önceki hücrelerin (özellikle Hücre 7 - eğitim) doğru çalıştığından emin olun.\")"
      ],
      "metadata": {
        "id": "TvOfvZv3OB8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hücre 11: Eğitim ve Çıkarım Sürelerinin Hesaplanması\n",
        "\n",
        "# time, torch, tqdm.auto, DataLoader zaten import edilmiş olmalı\n",
        "from tqdm.auto import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# 1. Eğitim Süresi\n",
        "calculated_training_time_value = None\n",
        "if 'training_time' in globals() and training_time is not None: # Hücre 7'de global yapılmıştı\n",
        "    calculated_training_time_value = training_time\n",
        "elif 'trainer' in globals() and trainer is not None and \\\n",
        "     hasattr(trainer.state, 'log_history') and trainer.state.log_history:\n",
        "    for log_entry in reversed(trainer.state.log_history):\n",
        "        if 'train_runtime' in log_entry: # Trainer'ın logladığı genel eğitim süresi\n",
        "            calculated_training_time_value = log_entry['train_runtime']\n",
        "            break\n",
        "\n",
        "if calculated_training_time_value is not None:\n",
        "    print(f\"Toplam Model Eğitim Süresi: {calculated_training_time_value:.2f} saniye ({calculated_training_time_value/60:.2f} dakika)\")\n",
        "else:\n",
        "    print(\"Eğitim süresi bilgisi `training_time` değişkeninden veya `log_history`'den alınamadı.\")\n",
        "\n",
        "# 2. Örnek Başına Ortalama Çıkarım Süresi (Test Seti Üzerinden)\n",
        "avg_inference_time_per_sample = None\n",
        "# Gerekli değişkenlerin varlığını kontrol edelim\n",
        "if 'model' in globals() and model is not None and \\\n",
        "   'tokenized_datasets' in globals() and \"test\" in tokenized_datasets and \\\n",
        "   'device' in globals() and 'tokenizer' in globals() and tokenizer is not None :\n",
        "\n",
        "    model.eval() # Modeli değerlendirme moduna al (dropout vb. katmanları etkisizleştirir)\n",
        "\n",
        "    # Modelin beklediği giriş sütunlarını belirle\n",
        "    if hasattr(tokenizer, 'model_input_names'):\n",
        "        model_input_names = tokenizer.model_input_names\n",
        "    else:\n",
        "        model_input_names = ['input_ids', 'attention_mask', 'token_type_ids']\n",
        "        if 'token_type_ids' not in tokenized_datasets[\"test\"].features: # Eğer veri setinde yoksa listeden çıkar\n",
        "            if 'token_type_ids' in model_input_names: model_input_names.remove('token_type_ids')\n",
        "\n",
        "    try:\n",
        "        # Sadece modelin ihtiyaç duyduğu sütunları içeren bir test seti kopyası oluştur\n",
        "        # ve formatını torch olarak ayarla\n",
        "        inference_ready_dataset = tokenized_datasets[\"test\"].select_columns(model_input_names)\n",
        "        inference_ready_dataset.set_format(\"torch\")\n",
        "    except Exception as e_cols: # select_columns yoksa veya başka bir hata olursa\n",
        "        print(f\"Uyarı: Çıkarım için sütun seçimi/formatlamada sorun ({e_cols}). Eski yöntem denenecek.\")\n",
        "        try:\n",
        "            current_test_set_columns = tokenized_datasets[\"test\"].column_names\n",
        "            cols_to_remove_for_inference = [col for col in current_test_set_columns if col not in model_input_names]\n",
        "            inference_ready_dataset = tokenized_datasets[\"test\"].remove_columns(cols_to_remove_for_inference)\n",
        "            inference_ready_dataset.set_format(\"torch\")\n",
        "        except Exception as e_format_fallback:\n",
        "            print(f\"Formatlama için fallback de başarısız: {e_format_fallback}. Orijinal test seti kullanılacak.\")\n",
        "            inference_ready_dataset = tokenized_datasets[\"test\"] # Son çare\n",
        "\n",
        "\n",
        "    inference_batch_size = 32 # Eğitimdeki eval_batch_size ile aynı olabilir\n",
        "    inference_dataloader = DataLoader(inference_ready_dataset, batch_size=inference_batch_size)\n",
        "\n",
        "    total_inference_time_val = 0.0 # İsim çakışmasını önlemek için farklı bir isim\n",
        "    num_samples_processed = 0\n",
        "\n",
        "    print(f\"\\nTest seti üzerinde çıkarım süresi hesaplanıyor (Batch Size: {inference_batch_size})...\")\n",
        "\n",
        "    with torch.no_grad(): # Gradyan hesaplamalarını kapat\n",
        "        for batch in tqdm(inference_dataloader, desc=\"Çıkarım Yapılıyor\"):\n",
        "            inputs_for_model = {}\n",
        "            valid_batch = True\n",
        "            for name in model_input_names:\n",
        "                if name in batch:\n",
        "                    inputs_for_model[name] = batch[name].to(device)\n",
        "                else: # Beklenen girdi batch'te yoksa\n",
        "                    # print(f\"Uyarı: Beklenen girdi '{name}' batch'te bulunamadı.\")\n",
        "                    # Bu durum genellikle collate_fn veya dataset formatıyla ilgilidir.\n",
        "                    # Eğer input_ids yoksa, bu batch'i atlamak daha güvenli olabilir.\n",
        "                    if name == 'input_ids': valid_batch = False\n",
        "                    break\n",
        "\n",
        "            if not valid_batch or not inputs_for_model :\n",
        "                try: num_in_batch = len(batch.get('input_ids', [])) # input_ids varsa onunla say\n",
        "                except: num_in_batch = 0\n",
        "                num_samples_processed += num_in_batch # Atlananları da sayıma ekleyelim (ya da işlemeyelim)\n",
        "                                                    # Şimdilik, eğer input_ids yoksa bu batch'i sayıma eklemeyelim.\n",
        "                if num_in_batch > 0 and not valid_batch : print(f\"Uyarı: Geçerli model girdisi eksik, {num_in_batch} örnek içeren bu yığın atlandı.\")\n",
        "                continue\n",
        "\n",
        "            current_batch_size = len(inputs_for_model['input_ids'])\n",
        "            num_samples_processed += current_batch_size\n",
        "\n",
        "            start_batch_time = time.perf_counter()\n",
        "            outputs = model(**inputs_for_model)\n",
        "            end_batch_time = time.perf_counter()\n",
        "\n",
        "            batch_time = end_batch_time - start_batch_time\n",
        "            total_inference_time_val += batch_time\n",
        "\n",
        "    if num_samples_processed > 0 and total_inference_time_val > 0 :\n",
        "        avg_inference_time_per_sample = total_inference_time_val / num_samples_processed\n",
        "        samples_per_second_inference = num_samples_processed / total_inference_time_val\n",
        "        print(f\"\\nToplam {num_samples_processed} örnek için çıkarım süresi: {total_inference_time_val:.4f} saniye\")\n",
        "        print(f\"Örnek başına ortalama çıkarım süresi: {avg_inference_time_per_sample:.6f} saniye/örnek\")\n",
        "        print(f\"Saniyede işlenen örnek sayısı (çıkarım): {samples_per_second_inference:.2f} örnek/saniye\")\n",
        "    elif num_samples_processed > 0 and total_inference_time_val == 0 :\n",
        "        print(f\"\\nToplam {num_samples_processed} örnek için çıkarım süresi çok kısa (< ölçülebilir hassasiyet), hız çok yüksek.\")\n",
        "        avg_inference_time_per_sample = 0.0\n",
        "    else:\n",
        "        print(\"Çıkarım için hiç örnek işlenemedi veya süre ölçülemedi.\")\n",
        "\n",
        "else:\n",
        "    print(\"Hata: Model, tokenize edilmiş test seti, tokenizer veya cihaz bilgisi bulunamadı.\")"
      ],
      "metadata": {
        "id": "npdqdHKZOJ5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}