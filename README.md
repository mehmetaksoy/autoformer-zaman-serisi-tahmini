# ğŸ¬ BERT ile IMDB Film YorumlarÄ± Duygu Analizi

Bu proje, BERT (Bidirectional Encoder Representations from Transformers) modelini kullanarak IMDB film yorumlarÄ± Ã¼zerinde duygu analizi gerÃ§ekleÅŸtiren kapsamlÄ± bir makine Ã¶ÄŸrenmesi uygulamasÄ±dÄ±r.

## ğŸ“‹ Proje Ã–zeti

Bu Ã§alÄ±ÅŸma, doÄŸal dil iÅŸleme (NLP) alanÄ±ndaki gÃ¼Ã§lÃ¼ transformatÃ¶r mimarilerinden biri olan BERT modelini kullanarak metin sÄ±nÄ±flandÄ±rma gÃ¶revini gerÃ§ekleÅŸtirir. IMDB film yorumlarÄ± veri seti Ã¼zerinde, yorumlarÄ±n pozitif mi yoksa negatif mi olduÄŸunu tahmin eden bir model geliÅŸtirilmiÅŸtir.

### ğŸ¯ Temel AmaÃ§lar
- TransformatÃ¶r modellerinin metin verileri Ã¼zerindeki etkinliÄŸini pratik bir Ã¶rnekle gÃ¶stermek
- Derin Ã¶ÄŸrenme projesinin tÃ¼m adÄ±mlarÄ±nÄ± kapsamlÄ± bir ÅŸekilde deneyimlemek
- Hugging Face ekosisteminin modern NLP kÃ¼tÃ¼phanelerinin kullanÄ±mÄ±nÄ± pekiÅŸtirmek

## ğŸ† Ana SonuÃ§lar

| Metrik | DeÄŸer |
|--------|-------|
| **Test DoÄŸruluÄŸu** | %92.04 |
| **Test F1-Score** | 0.9205 |
| **Test AUC** | 0.9758 |
| **EÄŸitim SÃ¼resi** | ~22.12 dakika |
| **Ã‡Ä±karÄ±m HÄ±zÄ±** | ~3,242 Ã¶rnek/saniye |

## ğŸ“Š Veri Seti

**IMDB Film YorumlarÄ± Veri Seti** kullanÄ±lmÄ±ÅŸtÄ±r:
- **Kaynak**: Hugging Face Datasets (`load_dataset("imdb")`)
- **Toplam Ã–rnek SayÄ±sÄ±**: 50,000 etiketli yorum
- **EÄŸitim Seti**: 20,000 Ã¶rnek (%80)
- **DoÄŸrulama Seti**: 5,000 Ã¶rnek (%20)
- **Test Seti**: 25,000 Ã¶rnek
- **SÄ±nÄ±flar**: Pozitif (1) ve Negatif (0) - Dengeli daÄŸÄ±lÄ±m

## ğŸ”§ Teknik Detaylar

### Model Mimarisi
- **Temel Model**: `bert-base-uncased`
- **SÄ±nÄ±flandÄ±rma KatmanÄ±**: 2 sÄ±nÄ±f (pozitif/negatif)
- **Tokenizasyon**: WordPiece, max_length=256
- **Parametre SayÄ±sÄ±**: ~110M

### EÄŸitim KonfigÃ¼rasyonu
```python
# Ana eÄŸitim parametreleri
num_train_epochs = 3
per_device_train_batch_size = 16
per_device_eval_batch_size = 32
learning_rate = 5e-5
warmup_steps = 500
weight_decay = 0.01
```

### KÃ¼tÃ¼phane VersiyonlarÄ±
Proje, aÅŸaÄŸÄ±daki stabil kÃ¼tÃ¼phane kombinasyonu ile geliÅŸtirilmiÅŸtir:
- **Python**: 3.11.11
- **PyTorch**: 2.5.1+cu124
- **Transformers**: 4.48.3
- **Datasets**: 3.6.0
- **NumPy**: 1.26.4

## ğŸš€ Kurulum ve Ã‡alÄ±ÅŸtÄ±rma

### 1. Gereksinimler
```bash
pip install torch transformers datasets scikit-learn matplotlib seaborn numpy pandas
```

### 2. Google Colab'da Ã‡alÄ±ÅŸtÄ±rma
1. Notebook dosyasÄ±nÄ± (`BERT_ile_Metin_SÄ±nÄ±flandÄ±rma_(IMDB_Duygu_Analizi)Kopya.ipynb`) Google Colab'a yÃ¼kleyin
2. GPU Runtime'Ä±nÄ± aktifleÅŸtirin: `Runtime > Change runtime type > Hardware accelerator > GPU`
3. **Ã–nemli**: Ä°lk hÃ¼creyi Ã§alÄ±ÅŸtÄ±rdÄ±ktan sonra runtime'Ä± yeniden baÅŸlatÄ±n
4. HÃ¼creleri sÄ±rasÄ±yla Ã§alÄ±ÅŸtÄ±rÄ±n

### 3. HÃ¼cre YapÄ±sÄ±
```
HÃ¼cre 1: KÃ¼tÃ¼phane kurulumu (sonrasÄ±nda runtime restart gerekli)
HÃ¼cre 2: Import iÅŸlemleri ve versiyon kontrolÃ¼
HÃ¼cre 3: IMDB veri setinin yÃ¼klenmesi
HÃ¼cre 4: Veri setinin eÄŸitim/doÄŸrulama/test olarak bÃ¶lÃ¼nmesi
HÃ¼cre 5: BERT tokenizer yÃ¼kleme ve tokenizasyon
HÃ¼cre 6: BERT modelinin yÃ¼klenmesi
HÃ¼cre 7: Model eÄŸitimi (epoch bazÄ±nda deÄŸerlendirme)
HÃ¼cre 8: Test seti performans deÄŸerlendirmesi
HÃ¼cre 9: KarmaÅŸÄ±klÄ±k matrisi ve ROC eÄŸrisi gÃ¶rselleÅŸtirmeleri
HÃ¼cre 10: EÄŸitim kayÄ±p grafikleri
HÃ¼cre 11: Ã‡Ä±karÄ±m hÄ±zÄ± hesaplamalarÄ±
```

## ğŸ“ˆ Performans Analizi

### Epoch BazÄ±nda GeliÅŸim
| Epoch | EÄŸitim KaybÄ± | DoÄŸrulama KaybÄ± | DoÄŸrulama DoÄŸruluÄŸu |
|-------|--------------|-----------------|---------------------|
| 1 | 0.3418 | 0.2475 | 0.9098 |
| 2 | 0.1790 | 0.2194 | 0.9182 |
| 3 | 0.0768 | 0.3635 | 0.9188 |

### Test Seti KarmaÅŸÄ±klÄ±k Matrisi
```
           Tahmin
GerÃ§ek    Neg    Pos
Neg     11490   1010
Pos       981  11519
```

### Ã–nemli GÃ¶zlemler
- Model 2. epoch sonrasÄ±nda aÅŸÄ±rÄ± Ã¶ÄŸrenme (overfitting) belirtileri gÃ¶stermiÅŸtir
- `load_best_model_at_end=True` ile en iyi performanslÄ± model kullanÄ±lmÄ±ÅŸtÄ±r
- Test seti Ã¼zerinde yÃ¼ksek genelleme performansÄ± elde edilmiÅŸtir

## ğŸ› ï¸ Teknik Ã–zellikler

### Metrik Hesaplama
Proje, kapsamlÄ± performans deÄŸerlendirmesi iÃ§in aÅŸaÄŸÄ±daki metrikleri hesaplar:
- **Accuracy**: Genel doÄŸruluk oranÄ±
- **Precision**: Pozitif tahminlerin doÄŸruluk oranÄ±
- **Recall (Sensitivity)**: Pozitif Ã¶rneklerin yakalanma oranÄ±
- **F1-Score**: Precision ve Recall'Ä±n harmonik ortalamasÄ±
- **Specificity**: Negatif Ã¶rneklerin doÄŸru tanÄ±nma oranÄ±
- **AUC**: ROC eÄŸrisi altÄ±nda kalan alan

### GÃ¶rselleÅŸtirmeler
- Epoch bazÄ±nda eÄŸitim ve doÄŸrulama kayÄ±p grafikleri
- DoÄŸrulama doÄŸruluk geliÅŸim grafiÄŸi
- Test seti karmaÅŸÄ±klÄ±k matrisi (heatmap)
- ROC eÄŸrisi ve AUC skoru

## ğŸ” Proje YapÄ±sÄ±

```
â”œâ”€â”€ BERT_ile_Metin_SÄ±nÄ±flandÄ±rma_(IMDB_Duygu_Analizi)Kopya.ipynb
â”œâ”€â”€ README.md
â””â”€â”€ results_epoch_evaluation/
    â”œâ”€â”€ best_model/           # En iyi model checkpoint'i
    â”œâ”€â”€ checkpoint-*/         # Epoch bazÄ±nda checkpoint'ler
    â””â”€â”€ runs/                 # TensorBoard loglarÄ±
```

## ğŸ“ Ã–ÄŸrenme Ã‡Ä±ktÄ±larÄ±

Bu proje aÅŸaÄŸÄ±daki konularda pratik deneyim saÄŸlar:
- **BERT modelinin fine-tuning sÃ¼reci**
- **Hugging Face Transformers ve Datasets kÃ¼tÃ¼phaneleri**
- **PyTorch ve Trainer API kullanÄ±mÄ±**
- **Metin Ã¶n iÅŸleme ve tokenizasyon**
- **Model deÄŸerlendirme ve gÃ¶rselleÅŸtirme teknikleri**
- **KÃ¼tÃ¼phane versiyon yÃ¶netimi ve hata ayÄ±klama**

## ğŸš¨ Ã–nemli Notlar

### KÃ¼tÃ¼phane UyumluluÄŸu
Proje geliÅŸimi sÄ±rasÄ±nda NumPy ve Datasets versiyonlarÄ± arasÄ±nda uyumluluk sorunlarÄ± yaÅŸanmÄ±ÅŸtÄ±r. Bu sorunlar, spesifik versiyonlarÄ±n sabitlenmesi ile Ã§Ã¶zÃ¼lmÃ¼ÅŸtÃ¼r.

### Bellek ve Hesaplama Gereksinimleri
- **GPU**: NVIDIA L4 (Colab Pro) Ã¶nerilir
- **RAM**: En az 12-16 GB
- **Depolama**: Model checkpoint'leri iÃ§in ~2-3 GB

## ğŸ”® GeliÅŸime AÃ§Ä±k Alanlar

1. **Model Ã‡eÅŸitlendirmesi**: RoBERTa, DeBERTa gibi diÄŸer transformatÃ¶r modelleri
2. **Hiperparametre Optimizasyonu**: Learning rate, batch size, epoch sayÄ±sÄ±
3. **Tokenizasyon Ä°yileÅŸtirmesi**: FarklÄ± max_length deÄŸerleri
4. **Regularizasyon**: Dropout, early stopping teknikleri
5. **Ensemble YÃ¶ntemleri**: Birden fazla modelin kombinasyonu

## ğŸ“ Lisans

Bu proje eÄŸitim amaÃ§lÄ± geliÅŸtirilmiÅŸtir ve MIT lisansÄ± altÄ±nda paylaÅŸÄ±lmaktadÄ±r.

## ğŸ‘¨â€ğŸ’» KatkÄ±da Bulunma

Proje geliÅŸtirmelerine katkÄ±da bulunmak iÃ§in:
1. Repository'yi fork edin
2. Feature branch oluÅŸturun (`git checkout -b feature/YeniOzellik`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -am 'Yeni Ã¶zellik eklendi'`)
4. Branch'inizi push edin (`git push origin feature/YeniOzellik`)
5. Pull Request oluÅŸturun

## ğŸ“ Ä°letiÅŸim

SorularÄ±nÄ±z iÃ§in GitHub Issues bÃ¶lÃ¼mÃ¼nÃ¼ kullanabilirsiniz.

---

*Bu proje, modern NLP tekniklerinin pratik uygulamasÄ±nÄ± gÃ¶stermek ve BERT modelinin gÃ¼Ã§lÃ¼ Ã¶zelliklerini keÅŸfetmek amacÄ±yla geliÅŸtirilmiÅŸtir.*